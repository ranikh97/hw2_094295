{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/StudentData/HW2/train/\"\n",
    "TestFolder  = \"/StudentData/HW2/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,root,transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.idxtoImage = {i:file for i,file in enumerate(os.listdir(self.root))}\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.idxtoImage)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        file = self.idxtoImage[idx]\n",
    "        image = Image.open(self.root+file).convert(\"RGB\")\n",
    "        if self.transform !=None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = int(file.split('_')[1].split('.')[0])\n",
    "        return image,label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((48,48)),transforms.ToTensor()])\n",
    "train_dataset = ImageDataset(ROOT,transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "test_dataset = ImageDataset(TestFolder,transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fc1 = nn.Linear(2*2*128, 256)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "  \n",
    "        out = self.fc1(out)\n",
    "        out = self.ReLU(out)\n",
    "        out = self.fc2(out)       \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gpu(x):\n",
    "    return x.cuda() if torch.cuda.is_available() else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  221058\n",
      "Num of trainable parameters : 221058\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model = to_gpu(model)\n",
    "    \n",
    "# convert all the weights tensors to cuda()\n",
    "# Loss and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print('number of parameters: ', sum(param.numel() for param in model.parameters()))\n",
    "print(f'Num of trainable parameters : {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [100/182] Loss: 0.1443\n",
      "Epoch [2/10], Iter [100/182] Loss: 0.1201\n",
      "Epoch [3/10], Iter [100/182] Loss: 0.1055\n",
      "Epoch [4/10], Iter [100/182] Loss: 0.0883\n",
      "Epoch [5/10], Iter [100/182] Loss: 0.0789\n",
      "Epoch [6/10], Iter [100/182] Loss: 0.0769\n",
      "Epoch [7/10], Iter [100/182] Loss: 0.0919\n",
      "Epoch [8/10], Iter [100/182] Loss: 0.0764\n",
      "Epoch [9/10], Iter [100/182] Loss: 0.0736\n",
      "Epoch [10/10], Iter [100/182] Loss: 0.0619\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = to_gpu(images)\n",
    "        labels = to_gpu(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1,\n",
    "                     len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6086\n",
      "Test Accuracy of the model on the test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "i=0\n",
    "for images, labels in test_loader:\n",
    "    images = to_gpu(images)\n",
    "    outputs = model(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total+= labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "    i+=1\n",
    "    \n",
    "print('Test Accuracy of the model on the test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2",
   "language": "python",
   "name": "hw2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
